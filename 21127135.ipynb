{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Đồ án 3: Linear Regression</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thông tin sinh viên\n",
    "\n",
    "- Họ và tên: Diệp Hữu Phúc\n",
    "- MSSV: 21127135\n",
    "- Lớp: 21CLC05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import thêm dữ thư viện nếu cần\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu bằng pandas\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Lấy các đặc trưng X và giá trị mục tiêu y cho các tập huấn luyện (train) và kiểm tra (test)\n",
    "X_train = train.iloc[:, :-1]    # Dataframe (chứa các đặc trưng huấn luyện)\n",
    "y_train = train.iloc[:, -1]     # Series    (chứa 1 giá trị mục tiêu kiểm tra)\n",
    "\n",
    "X_test = test.iloc[:, :-1]      # Dataframe (chứa các đặc trưng kiểm tra)\n",
    "y_test = test.iloc[:, -1]       # Series    (chứa 1 giá trị mục tiêu kiểm tra)\n",
    "\n",
    "# Sinh viên có thể sử dụng các khác nếu cần\n",
    "# 1a. 11 đặc trưng đầu tiên (Gender, ..., Domain)\n",
    "X_1a_train = train.iloc[:, :11]\n",
    "X_1a_test = test.iloc[:, :11]\n",
    "# 1b. conscientiousness, agreeableness, extraversion, nueroticism, openess_to_experience\n",
    "train_1b = train.loc[:, 'conscientiousness':]\n",
    "# 1c. English, Logical, Quant\n",
    "train_1c = train.loc[:, ['English', 'Logical', 'Quant', 'Salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt hàm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các hàm cần thiết ở đây\n",
    "class OLSLinearRegression:\n",
    "    def fit(self, X, y):\n",
    "        X_pinv = np.linalg.inv(X.T @ X) @ X.T    # np.linalg.pinv(X)\n",
    "        self.w = X_pinv @ y\n",
    "        return self\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sum(self.w.ravel() * X, axis=1)\n",
    "\n",
    "def mae(y, y_hat):\n",
    "    return np.mean(np.abs(y.ravel() - y_hat.ravel()))\n",
    "\n",
    "def kfold_traits(train:pd.DataFrame, k_fold:int=5, seed:int=42, trait_label:str='Trait'):\n",
    "    '''\n",
    "    > train:pd.DataFrame - The training set.\n",
    "    > k_fold:int - The number of tests, or splits, or folds.\n",
    "    > seed:int - The seed for random_state, use None for irreproducible results.\n",
    "    > trait_label:str - The column name for the traits.\n",
    "    < fit_trait:list - 1st element is the name of the fittest trait, 2nd is its avg_MAE.\n",
    "    < avg_MAEs:pd.DataFrame - Table of every trait and its avg_MAE.\n",
    "    '''\n",
    "    split_MAEs = []\n",
    "    traits = train.iloc[:, :-1].columns.values\n",
    "    train_shuffle = train.sample(frac=1, replace=False, random_state=seed)\n",
    "    train_splits = np.array_split(train_shuffle, k_fold)\n",
    "    for i in range(k_fold):\n",
    "        subtrain = pd.concat(train_splits[:i] + train_splits[i + 1:])\n",
    "        X_subtrain = subtrain.iloc[:, :-1]\n",
    "        y_subtrain = subtrain.iloc[:, -1]\n",
    "        X_subtest = train_splits[i].iloc[:, :-1]\n",
    "        y_subtest = train_splits[i].iloc[:, -1]\n",
    "\n",
    "        MAEs = []\n",
    "        for tr in traits:\n",
    "            X_tr_train = pd.Series.to_frame(X_subtrain[tr])\n",
    "            X_tr_test = pd.Series.to_frame(X_subtest[tr])\n",
    "            model_tr = OLSLinearRegression().fit(X_tr_train, y_subtrain)\n",
    "            y_tr_hat = model_tr.predict(X_tr_test)\n",
    "            MAEs.append(mae(y_subtest, y_tr_hat))\n",
    "        split_MAEs.append(MAEs)\n",
    "\n",
    "    avg_MAEs = np.array(split_MAEs).mean(axis=0).tolist()\n",
    "    avg_MAEs = [[tr, avg] for tr, avg in zip(traits, avg_MAEs)]\n",
    "    fit_trait = sorted(avg_MAEs, key=lambda x: x[1])[0]\n",
    "    avg_MAEs = pd.DataFrame(avg_MAEs, columns=[trait_label, 'Average MAE'])\n",
    "    return fit_trait, avg_MAEs\n",
    "\n",
    "def stepwise_regress(X_train:pd.DataFrame, y_train:pd.Series, pval_max:float=0.05):\n",
    "    '''\n",
    "    > X_train:pd.DataFrame - The training features set\n",
    "    > y_train:pd.Series - The target variable, or feature, set\n",
    "    > pval_max:float - The upper limit of p-values\n",
    "    < sig_traits:list(str) - Names of all the significant features\n",
    "    '''\n",
    "    X_st_train = X_train.copy()\n",
    "    stats = sm.OLS(y_train, X_st_train).fit()\n",
    "    while not all(stats.pvalues <= pval_max):\n",
    "        trait_max = stats.pvalues[stats.pvalues == max(stats.pvalues)]\n",
    "        X_st_train.drop(columns=trait_max.index[0], inplace=True)\n",
    "        stats = sm.OLS(y_train, X_st_train).fit()\n",
    "    return stats.model.exog_names + [y_train.name]\n",
    "\n",
    "def corr_regress(train:pd.DataFrame, corr_max:float=0.9):\n",
    "    '''\n",
    "    > train:pd.DataFrame - The training set\n",
    "    > corr_max:float - The upper limit of correlation values\n",
    "    < corr_mat:pd.DataFrame - The correlation matrix\n",
    "    < sat_traits:list(str) - Names of all the satisfied features\n",
    "    '''\n",
    "    corr_mat = train.corr()\n",
    "    columns = np.full((corr_mat.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr_mat.shape[0]):\n",
    "        for j in range(i + 1, corr_mat.shape[0]):\n",
    "            if corr_mat.iloc[i, j] >= corr_max:\n",
    "                if columns[j]: columns[j] = False\n",
    "    return corr_mat, train.columns[columns].values\n",
    "\n",
    "def kfold_models(model_builders:list, train:pd.DataFrame, k_fold:int=5, seed:int=42):\n",
    "    '''\n",
    "    > model_builders:list - Array of every model and its builder.\n",
    "    > train:pd.DataFrame - The training set.\n",
    "    > k_fold:int - The number of tests, or splits, or folds.\n",
    "    > seed:int - The seed for random_state, use None for irreproducible results.\n",
    "    < fit_model:list - 1st element is the name of the fittest model, 2nd is its avg_MAE.\n",
    "    < avg_MAEs:pd.DataFrame - Table of every model and its avg_MAE.\n",
    "    '''\n",
    "    split_MAEs = []\n",
    "    train_shuffle = train.sample(frac=1, replace=False, random_state=seed)\n",
    "    train_splits = np.array_split(train_shuffle, k_fold)\n",
    "    for i in range(k_fold):\n",
    "        subtrain = pd.concat(train_splits[:i] + train_splits[i + 1:])\n",
    "        X_subtrain = subtrain.iloc[:, :-1]\n",
    "        y_subtrain = subtrain.iloc[:, -1]\n",
    "        X_subtest = train_splits[i].iloc[:, :-1]\n",
    "        y_subtest = train_splits[i].iloc[:, -1]\n",
    "\n",
    "        MAEs = []\n",
    "        for build in model_builders:\n",
    "            model, X_mod_test = build[1](X_subtrain, y_subtrain, X_subtest)[:2]\n",
    "            y_mod_hat = model.predict(X_mod_test)\n",
    "            MAEs.append(mae(y_subtest, y_mod_hat))\n",
    "        split_MAEs.append(MAEs)\n",
    "\n",
    "    avg_MAEs = np.average(np.array(split_MAEs), axis=0).tolist()\n",
    "    models = [mod[0] for mod in model_builders]\n",
    "    avg_MAEs = [[mod, avg] for mod, avg in zip(models, avg_MAEs)]\n",
    "    fit_model = sorted(avg_MAEs, key=lambda x: x[1])[0]\n",
    "    avg_MAEs = pd.DataFrame(avg_MAEs, columns=['Model', 'Average MAE'])\n",
    "    return fit_model, avg_MAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1a: Sử dụng toàn bộ 11 đặc trưng đầu tiên `Gender`, `10percentage`, `12percentage`, `CollegeTier`, `Degree`, `collegeGPA`, `CollegeCityTier`, `English`, `Logical`, `Quant`, `Domain` (2 điểm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1a\n",
    "model_1a = OLSLinearRegression().fit(X_1a_train, y_train)\n",
    "params_1a = model_1a.get_params()\n",
    "params_1a.index = X_1a_train.columns.values\n",
    "params_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra\n",
    "y_hat = model_1a.predict(X_1a_test)\n",
    "print(f'MAE: {mae(y_test, y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = -22756.513\\times\\text{Gender} + 804.503\\times\\text{10percentage} + 1294.655\\times\\text{12percentage} - 91781.898\\times\\text{CollegeTier} \\\\ + 23182.389\\times\\text{Degree} + 1437.549\\times\\text{collegeGPA} - 8570.662\\times\\text{CollegeCityTier} + 147.858\\times\\text{English} \\\\ + 152.888\\times\\text{Logical} + 117.222\\times\\text{Quant} + 34552.286\\times\\text{Domain}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1b: Xây dựng mô hình sử dụng duy nhất 1 đặc trưng tính cách với các đặc trưng tính cách gồm `conscientiousness`, `agreeableness`, `extraversion`, `nueroticism`, `openess_to_experience`, tìm mô hình cho kết quả tốt nhất (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: khi sử dụng cross-validation, sinh viên cần xáo trộn dữ liệu 1 lần duy nhất và thực hiện trên toàn bộ đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1b\n",
    "# Tìm ra đặc trưng tốt nhất\n",
    "# In ra các kết quả cross-validation như yêu cầu\n",
    "fit_trait, avg_MAEs = kfold_traits(train_1b, trait_label='Personality')\n",
    "print(f'The fittest personality: {fit_trait[0]}')\n",
    "avg_MAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện lại mô hình best_personality_feature_model với đặc trưng tốt nhất trên toàn bộ tập huấn luyện\n",
    "X_pers_train = pd.Series.to_frame(X_train[fit_trait[0]])\n",
    "best_personality_feature_model = OLSLinearRegression().fit(X_pers_train, y_train)\n",
    "best_personality_feature_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra với mô hình best_personality_feature_model\n",
    "X_pers_test = pd.Series.to_frame(X_test[fit_trait[0]])\n",
    "y_hat = best_personality_feature_model.predict(X_pers_test)\n",
    "print(f'MAE: {mae(y_test, y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = -56546.304\\times\\text{nueroticism}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1c: Xây dựng mô hình sử dụng duy nhất 1 đặc trưng `English`, `Logical`, `Quant`, tìm mô hình cho kết quả tốt nhất (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: khi sử dụng cross-validation, sinh viên cần xáo trộn dữ liệu 1 lần duy nhất và thực hiện trên toàn bộ đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1c\n",
    "# Tìm ra đặc trưng tốt nhất\n",
    "# In ra các kết quả cross-validation như yêu cầu\n",
    "fit_trait, avg_MAEs = kfold_traits(train_1c, trait_label='Skill')\n",
    "print(f'The fittest skill: {fit_trait[0]}')\n",
    "avg_MAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện lại mô hình best_skill_feature_model với đặc trưng tốt nhất trên toàn bộ tập huấn luyện\n",
    "X_sk_train = pd.Series.to_frame(X_train[fit_trait[0]])\n",
    "best_skill_feature_model = OLSLinearRegression().fit(X_sk_train, y_train)\n",
    "best_skill_feature_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra với mô hình best_skill_feature_model\n",
    "X_sk_test = pd.Series.to_frame(X_test[fit_trait[0]])\n",
    "y_hat = best_skill_feature_model.predict(X_sk_test)\n",
    "print(f'MAE: {mae(y_test, y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = 585.895\\times\\text{Quant}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1d: Sinh viên tự xây dựng mô hình, tìm mô hình cho kết quả tốt nhất (3 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: khi sử dụng cross-validation, sinh viên cần xáo trộn dữ liệu 1 lần duy nhất và thực hiện trên toàn bộ $m$ mô hình mà sinh viên thiết kế"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tìm mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trình bày các phần tìm ra mô hình\n",
    "# MODEL 1 [rf_1dm1] - Using Stepwise Regression to filter out unimportant features.\n",
    "def build_1dm1_stepReg(X_train:pd.DataFrame, y_train:pd.Series, X_test:pd.DataFrame):\n",
    "    traits = stepwise_regress(X_train, y_train)\n",
    "    X_1dm1_train = X_train.loc[:, traits[:-1]]\n",
    "    X_1dm1_test = X_test.loc[:, traits[:-1]]\n",
    "    model_1dm1 = OLSLinearRegression().fit(X_1dm1_train, y_train)\n",
    "    return model_1dm1, X_1dm1_test\n",
    "\n",
    "# MODEL 2 [rf_1dm2] - Using Correlation Matrix to remove features. For every pair of\n",
    "#   features having high correlation value, one of the two will be discarded.\n",
    "def build_1dm2_corrMat(X_train:pd.DataFrame, y_train:pd.Series, X_test:pd.DataFrame):\n",
    "    corr_mat, traits = corr_regress(pd.concat([X_train, y_train], axis=1))\n",
    "    X_1dm2_train = X_train.loc[:, traits[:-1]]\n",
    "    X_1dm2_test = X_test.loc[:, traits[:-1]]\n",
    "    model_1dm2 = OLSLinearRegression().fit(X_1dm2_train, y_train)\n",
    "    return model_1dm2, X_1dm2_test, corr_mat\n",
    "\n",
    "corr_mat = train.corr()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(corr_mat, annot=True, linewidths=.5)\n",
    "plt.title('train.csv Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# MODEL 3 - Grouping features based on semantics. This model is quite silly, it drew\n",
    "#   inspiration from the above tasks.\n",
    "def build_1dm3_featGroup(X_train:pd.DataFrame, y_train:pd.Series, X_test:pd.DataFrame):\n",
    "    X_1dm3_train = pd.concat([X_train.loc[:, 'Gender':'CollegeCityTier'].sum(axis=1),\n",
    "                            X_train.loc[:, 'English':'Quant'].sum(axis=1),\n",
    "                            X_train.loc[:, 'Domain':'CivilEngg'].sum(axis=1),\n",
    "                            X_train.loc[:, 'conscientiousness':'openess_to_experience'].sum(axis=1)],\n",
    "                            axis=1, keys=['Gen2Col', 'Eng2Qua', 'Dom2Civ', 'con2ope'])\n",
    "    X_1dm3_test = pd.concat([X_test.loc[:, 'Gender':'CollegeCityTier'].sum(axis=1),\n",
    "                            X_test.loc[:, 'English':'Quant'].sum(axis=1),\n",
    "                            X_test.loc[:, 'Domain':'CivilEngg'].sum(axis=1),\n",
    "                            X_test.loc[:, 'conscientiousness':'openess_to_experience'].sum(axis=1)],\n",
    "                            axis=1, keys=['Gen2Col', 'Eng2Qua', 'Dom2Civ', 'con2ope'])\n",
    "    model_1dm3 = OLSLinearRegression().fit(X_1dm3_train, y_train)\n",
    "    return model_1dm3, X_1dm3_test\n",
    "\n",
    "# MODEL 4 [rf_1dm2] - Combining Correlation Matrix and Stepwise Regression.\n",
    "def build_1dm4_corrStep(X_train:pd.DataFrame, y_train:pd.Series, X_test:pd.DataFrame):\n",
    "    corr_mat, traits = corr_regress(pd.concat([X_train, y_train], axis=1))\n",
    "    X_corr_train = X_train.loc[:, traits[:-1]]\n",
    "    X_corr_test = X_test.loc[:, traits[:-1]]\n",
    "    return list(build_1dm1_stepReg(X_corr_train, y_train, X_corr_test)) + [corr_mat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thử nghiệm, so sánh các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1d\n",
    "# Tìm ra mô hình tốt nhất (tự thiết kế bởi sinh viên)\n",
    "# In ra các kết quả cross-validation như yêu cầu\n",
    "model_builders = [['1dm1 Stepwise Regression', build_1dm1_stepReg],\n",
    "                  ['1dm2 Correlation Matrix', build_1dm2_corrMat],\n",
    "                  ['1dm3 Feature Grouping', build_1dm3_featGroup],\n",
    "                  ['1dm4 Correlation & Stepwise', build_1dm4_corrStep]]\n",
    "fit_model, avg_MAEs = kfold_models(model_builders, train)\n",
    "print(f'The fittest model: {fit_model[0]}')\n",
    "avg_MAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện lại mô hình my_best_model trên toàn bộ tập huấn luyện\n",
    "my_best_model, X_bm_test = build_1dm2_corrMat(X_train, y_train, X_test)[:2]\n",
    "params_bm = my_best_model.get_params()\n",
    "params_bm.index = X_bm_test.columns.values\n",
    "params_bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra với mô hình my_best_model\n",
    "y_bm_hat = my_best_model.predict(X_bm_test)\n",
    "print(f'MAE: {mae(y_test, y_bm_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = -23874.542\\times\\text{Gender} + 898.576\\times\\text{10percentage} + 1203.496\\times\\text{12percentage} - 83592.388\\times\\text{CollegeTier} \\\\ + 11515.431\\times\\text{Degree} + 1626.519\\times\\text{collegeGPA} - 5717.734\\times\\text{CollegeCityTier} + 153.435\\times\\text{English} \\\\ + 120.511\\times\\text{Logical} + 102.581\\times\\text{Quant} + 27939.640\\times\\text{Domain} + 76.730\\times\\text{ComputerProgramming} \\\\ - 47.747\\times\\text{ElectronicsAndSemicon} - 177.388\\times\\text{ComputerScience} + 33.933\\times\\text{MechanicalEngg} \\\\ - 151.471\\times\\text{ElectricalEngg} - 64.198\\times\\text{TelecomEngg} + 145.895\\times\\text{CivilEngg} \\\\ - 19814.830\\times\\text{conscientiousness} + 15503.267\\times\\text{agreeableness} + 4908.582\\times\\text{extraversion} \\\\ - 10661.029\\times\\text{nueroticism} - 5815.021\\times\\text{openess\\_to\\_experience}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "## 1a. First 11 features (Gender, ..., Domain)\n",
    "- `lab04.ipynb` provided by Lecturer Phan Thị Phương Uyên.\n",
    "\n",
    "## 1b. conscientiousness, agreeableness, extraversion, nueroticism, openess_to_experience\n",
    "- https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "- https://grsahagian.medium.com/what-is-random-state-42-d803402ee76b\n",
    "- https://stackoverflow.com/a/17315875\n",
    "\n",
    "## 1d. Building models and finding the best one\n",
    "### Model 1 - Stepwise Regression\n",
    "- https://youtu.be/-inJu1jHqb8\n",
    "- https://youtu.be/An40g_j1dHA\n",
    "- https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922 [rf_1dm1]\n",
    "- https://stackoverflow.com/a/30523731\n",
    "- https://stackoverflow.com/q/11836286\n",
    "\n",
    "### Model 2 - Correlation Matrix\n",
    "- https://androidkt.com/find-correlation-between-features-and-target-using-the-correlation-matrix/\n",
    "- https://vishalramesh.substack.com/p/feature-selection-correlation-and-p-value-da8921bfb3cf?s=w [rf_1dm2]\n",
    "\n",
    "### Model 3 - Feature Grouping\n",
    "- https://stackoverflow.com/a/42063749\n",
    "\n",
    "## Appendix A: Concepts that I failed to implement\n",
    "- https://youtu.be/fyRubPKgVoY\n",
    "- https://stats.stackexchange.com/a/18852\n",
    "- https://stats.stackexchange.com/a/11373\n",
    "- https://machinelearningmastery.com/how-to-transform-target-variables-for-regression-with-scikit-learn/\n",
    "- https://towardsdatascience.com/feature-transformation-for-multiple-linear-regression-in-python-8648ddf070b8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15af99fd1a1a3f0a3416ea421564e792a8676a13670c2eed127d89ab0518a27b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
